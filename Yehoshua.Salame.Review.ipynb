{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Yehoshua.Salame.Review.ipynb","provenance":[],"authorship_tag":"ABX9TyNcgfkFGvGgwnl3INqo+ZgR"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mPfzruN1RWnu"},"source":["Review Homework Code, presented in steps 1-5.\n"]},{"cell_type":"code","metadata":{"id":"Kgwr0jloGEvi","executionInfo":{"status":"ok","timestamp":1603951095846,"user_tz":240,"elapsed":343,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}}},"source":["import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U9CAd479R13P"},"source":["Part 1: Write code to load a dataset and split it into X_train, y_train, X_test, y_test."]},{"cell_type":"code","metadata":{"id":"ISHpsSU_Olys","executionInfo":{"status":"ok","timestamp":1603951118121,"user_tz":240,"elapsed":22611,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"29d6a29d-10ce-4ae1-e688-69298e67f7f9","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Import MNIST dataset\n","from sklearn.datasets import fetch_openml\n","print(\"Importing dataset\")\n","mnist = fetch_openml('mnist_784', version=1)\n","print(\"Finished importing dataset\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Importing dataset\n","Finished importing dataset\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iE678lR8OxcB","executionInfo":{"status":"ok","timestamp":1603951118122,"user_tz":240,"elapsed":22606,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"cc021440-5d80-4aaf-bdde-7afd6ef8c1fa","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Assigning data and labels\n","X, y = mnist[\"data\"], mnist[\"target\"]\n","# Already split and shuffled, just assign\n","print(\"Splitting into training and test set (NOTE: Only taking first 30k for training, 5k for testing aka half\")\n","X_train, X_test, y_train, y_test = X[:30000], X[30000:35000], y[:30000], y[30000:35000]\n","print(\"Finished importing dataset\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Splitting into training and test set (NOTE: Only taking first 30k for training, 5k for testing akak half\n","Finished importing dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aVwqVcNNR9RQ"},"source":["Part 2: Write a pipeline to preprocess your features. Apply it to your train and test set."]},{"cell_type":"code","metadata":{"id":"fG2ZA54xSBYQ","executionInfo":{"status":"ok","timestamp":1603951168678,"user_tz":240,"elapsed":73156,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"51cddfd2-e43f-4e4e-a944-0419839b076b","colab":{"base_uri":"https://localhost:8080/"}},"source":["from sklearn.svm import LinearSVC\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","\n","print(\"Creating pipeline\")\n","pipeline = Pipeline([\n","                (\"scaler\", StandardScaler()),\n","                (\"linear_svc\", LinearSVC(dual=False, multi_class=\"ovr\", random_state=42))\n","])\n","print(\"Finished creating pipeline\")\n","print(\"Training pipeline on training set\")\n","pipeline.fit(X_train, y_train)\n","print(\"Finished training\")\n","print(\"Testing on test set\")\n","pipeline_score = pipeline.score(X_test, y_test)\n","print(\"Finished testing on test set\")\n","print(\"Score: \", pipeline_score)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Creating pipeline\n","Finished creating pipeline\n","Training pipeline on training set\n","Finished training\n","Testing on test set\n","Finished testing on test set\n","Score:  0.8958\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gl3L7FLmTgge"},"source":["Part 3: Write code to find good hyperparameters for a given model."]},{"cell_type":"code","metadata":{"id":"3zo5EDowbKgb","executionInfo":{"status":"ok","timestamp":1603951168678,"user_tz":240,"elapsed":73149,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"9bbe2666-94ac-403c-c81d-1d5e091dfb79","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Get keys to find which parameters to pass the classifier in the pipeline\n","pipeline.get_params().keys()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['memory', 'steps', 'verbose', 'scaler', 'linear_svc', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'linear_svc__C', 'linear_svc__class_weight', 'linear_svc__dual', 'linear_svc__fit_intercept', 'linear_svc__intercept_scaling', 'linear_svc__loss', 'linear_svc__max_iter', 'linear_svc__multi_class', 'linear_svc__penalty', 'linear_svc__random_state', 'linear_svc__tol', 'linear_svc__verbose'])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"2brJAxGSTfxe","executionInfo":{"status":"ok","timestamp":1603952598103,"user_tz":240,"elapsed":1502569,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"7fd0fdf7-f27e-4f73-a424-20502b4e3886","colab":{"base_uri":"https://localhost:8080/"}},"source":["from sklearn.model_selection import RandomizedSearchCV\n","# Create parameters to check\n","param_rnd = [\n","             {'linear_svc__C': [.01, .1, 1, 10, 100]},\n","             {'linear_svc__tol': [0.01, 0.025, 0.1, 0.25, 1]}\n","]\n","\n","# Search through param_rnd with cross-validation \n","rnd_clf = RandomizedSearchCV(pipeline, param_rnd, n_iter=10, n_jobs=10, random_state=42)\n","print(\"Training rnd_clf\")\n","rnd_clf.fit(X_train, y_train)\n","print(\"Finished training rnd_clf\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Training rnd_clf\n","Finished training rnd_clf\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eeHivnbrdbBE"},"source":["Part 4: Write code to evaluate your model."]},{"cell_type":"code","metadata":{"id":"X8nAfAfuezTP","executionInfo":{"status":"ok","timestamp":1603952598105,"user_tz":240,"elapsed":1502569,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"e7c1aba2-22e2-4196-c36c-0aa7c6d612fa","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Print best hyperparameters and score\n","print(\"Best hyperparameters: \", rnd_clf.best_params_)\n","print(\"Best score: \", rnd_clf.best_score_)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Best hyperparameters: \n","{'linear_svc__C': 0.01}\n","Best score: \n","0.9017333333333333\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tC6X4dYRuN4l"},"source":["(Run locally)<br>\n","Best hyperparameters:<br>\n","{'linear_svc__C': 0.01}<br>\n","Best score:<br>\n","0.9017333333333333<br><br>\n","NOTE: Clearly the tolerance wasn't set properly, so I need to reassign the pipeline so as not to have the svc have the tol hyperparameter. However with more restricted tolerances running time will likely increase, so hold steady until I get new results."]},{"cell_type":"code","metadata":{"id":"XQxf3veJc4pA","executionInfo":{"status":"ok","timestamp":1603952598106,"user_tz":240,"elapsed":1502569,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"d16bbfc6-7825-4571-cb23-29b9055e956f","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Test and show accuracy. Need to change how model is evaluated. Will use F1 score probably.\n","print(\"Testing rnd_clf\")\n","rnd_clf_score = rnd_clf.score(X_test, y_test)\n","print(\"Finished testing rnd_clf\")\n","print(\"Score: \", rnd_clf_score)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Testing rnd_clf\n","Finished testing rnd_clf\n","Score:  0.8948\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k6IWMUfGu0Jk"},"source":["(Run locally)<br>\n","Testing rnd_clf<br>\n","Finished testing rnd_clf<br>\n","Score:  0.8948"]},{"cell_type":"markdown","metadata":{"id":"gAj1Edncctg0"},"source":["Part 5: Write code to create an instance of each of the models we covered, find good hyperparameters using a subset of your data, train it using cross-validation and find its performance, and evaluate it on your test set.<br><br>\n","Working on it."]},{"cell_type":"code","metadata":{"id":"MyJJoYkViVe9","executionInfo":{"status":"ok","timestamp":1603952598239,"user_tz":240,"elapsed":1502701,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"c86cc5da-f9fc-42c9-dd20-5e1ab47b095e","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Taking smaller split of data for speedrunning because #computerlivesmatter\n","print(\"Splitting into training and test set (NOTE: Only taking first 9k for training, 1k for testing\")\n","X_train, X_test, y_train, y_test = X[:9000], X[9000:10000], y[:9000], y[9000:10000]"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Splitting into training and test set (NOTE: Only taking first 9k for training, 1k for testing\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dsudokBjjbla","executionInfo":{"status":"ok","timestamp":1603952598240,"user_tz":240,"elapsed":1502701,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}}},"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Classifier instantiation, as well as list for looping purposes. \n","# Likely able to loop through the classifiers for grid search,\n","# but unsure how to loop through param_dist or how to pass those on to a pipeline.\n","# May simply create an individual param_dist variable for each model as they require\n","# creating those distributions manually anyway.\n","\n","log_clf = LogisticRegression()\n","svc_clf = SVC()\n","linear_svc_clf = LinearSVC()\n","sgd_clf = SGDClassifier()\n","dt_clf = DecisionTreeClassifier()\n","rf_clf = RandomForestClassifier()\n","knn_clf = KNeighborsClassifier()\n","\n","# classifiers list\n","clf_list = [log_clf, svc_clf, linear_svc_clf, sgd_clf, dt_clf, rf_clf, knn_clf]"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rx9BeZPZdQ1q","executionInfo":{"status":"ok","timestamp":1603960790222,"user_tz":240,"elapsed":262,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"8ffa1a07-c7b3-47aa-ed22-8288b5bda430","colab":{"base_uri":"https://localhost:8080/"}},"source":["pipeline = Pipeline([\n","                (\"scaler\", StandardScaler()),\n","                (\"classifier\", \"passthrough\")\n","])\n","pipeline.get_params().keys()"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['memory', 'steps', 'verbose', 'scaler', 'classifier', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std'])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"VHnRiIft4X29","executionInfo":{"status":"ok","timestamp":1603960413706,"user_tz":240,"elapsed":239,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}}},"source":["# Individual param_dist variable for each model\n","# NEEDS DOING (possibly last thing, then note cleanup and print statement removal or on/off switch)\n","log_param_dist = [\n","             {'classifier': clf_list[0]}\n","]\n","svc_param_dist = [\n","             {'classifier': clf_list[1]}\n","]\n","linear_svc_param_dist = [\n","             {'classifier': clf_list[2]}\n","]\n","sgd_param_dist = [\n","             {'classifier': clf_list[3]}\n","]\n","dt_param_dist = [\n","             {'classifier': clf_list[4]}\n","]\n","rf_param_dist = [\n","             {'classifier': clf_list[5]}\n","]\n","knn_param_dist = [\n","             {'classifier': clf_list[6]}\n","]\n","\n","# hyperparemeter distributions list\n","param_dist_list = [log_param_dist, svc_param_dist, linear_svc_param_dist, \n","                   sgd_param_dist, dt_param_dist, rf_param_dist, knn_param_dist]"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeKk3_Ir3Rxd","executionInfo":{"status":"error","timestamp":1603960535250,"user_tz":240,"elapsed":285,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"999abef9-ed5e-4973-d7f0-6df4f509e148","colab":{"base_uri":"https://localhost:8080/","height":649}},"source":["from sklearn.model_selection import RandomizedSearchCV\n","# Loop through each classifier, train, cross-validate, and test each.\n","for i in range(7):\n","    # Get classifier and parameters from lists\n","    clf = clf_list[i]\n","    param_dist = param_dist_list[i]\n","    \n","    print(\"Processing \", clf, \": \")\n","    \n","    # Perform search and cross-validation\n","    rnd_search = RandomizedSearchCV(pipeline, param_dist, n_iter=5, n_jobs=-1, random_state=42)\n","    print(\"Training \", clf, \": \")\n","    rnd_search.fit(X_train, y_train)\n","    print(\"Finished training \", clf)\n","    \n","    # Print best hyperparameters and score\n","    print(\"Best hyperparameters: \", rnd_search.best_params_)\n","    print(\"Best score: \", rnd_search.best_score_)\n","    \n","    # Test and show accuracy. Need to change how model is evaluated. Will use F1 score probably.\n","    print(\"Testing rnd_search\")\n","    grid_search_score = rnd_search.score(X_test, y_test)\n","    print(\"Finished testing rnd_search\")\n","    print(\"Score: \", rnd_search_score) "],"execution_count":37,"outputs":[{"output_type":"stream","text":["Processing  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False) : \n","Training  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False) : \n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-3ae621ab9ffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrnd_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mrnd_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished training \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0;32m--> 629\u001b[0;31m             self.estimator, scoring=self.scoring)\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[0;34m(estimator, scoring)\u001b[0m\n\u001b[1;32m    471\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[1;32m    472\u001b[0m                                                           str):\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                 % estimator)\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         raise ValueError(\"For evaluating multiple scores, use \"\n","\u001b[0;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator Pipeline(memory=None,\n         steps=[('scaler',\n                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n                ('classifier', 'passthrough')],\n         verbose=False) does not."]}]}]}
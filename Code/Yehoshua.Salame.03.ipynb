{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Yehoshua.Salame.03.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"hRvGSuDuKS_Z"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I9kvIaySPG1U","executionInfo":{"status":"ok","timestamp":1600927095102,"user_tz":240,"elapsed":23913,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"4e8560e4-69c0-453e-a195-0aa7253f6d91","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.datasets import fetch_openml\n","mnist = fetch_openml('mnist_784', version=1)\n","mnist.keys()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'DESCR', 'details', 'categories', 'url'])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"jr_yscMLKfsv","executionInfo":{"status":"ok","timestamp":1600921049065,"user_tz":240,"elapsed":16700,"user":{"displayName":"Yehoshua S.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8lXE6bUl_0TcnqO4NoWnlz4J0Gza_xEKWw8yJ=s64","userId":"05463914661174493943"}},"outputId":"37370ab9-90ee-4b16-c3a1-2eb604cba3eb","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["X, y = mnist[\"data\"], mnist[\"target\"]\n","print(X.shape)\n","print(y.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(70000, 784)\n","(70000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oGH0oOjmLY_j"},"source":["# MNIST is already split into training (first 60,000 instances) and test\n","# already shuffled\n","X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PIXDvE86SCku"},"source":["# Improve accuracy by scaling inputs (as discussed in Chapter 2)\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","\n","# Original version which I'm fairly sure doesn't actually take effect, which seems stupid\n","#X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n","\n","# My version, which I hope works and actually scales the data properly\n","X_train = scaler.fit_transform(X_train.astype(np.float64))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iEhSR15j7E9d"},"source":["# RandomizedSearch for KNNClassifier on hyperparameteres n_neighbors and weights (gridsearch takes too long)\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","knn_clf = KNeighborsClassifier()\n","hyperparameters = { 'n_neighbors': [1,2,3,4,5,6,7,8,9,10], 'weights': ['uniform', 'distance'] }\n","# According to the book, n_neighbors=4, weights=\"distance\" achieves enough accuracy, \n","# so even if the code runs into issues it has the potential to pass 97%+\n","rnd_search = RandomizedSearchCV(knn_clf, hyperparameters, random_state=42, n_iter=5, n_jobs=6, cv=3, verbose=3)\n","rnd_search.fit(X_train, y_train)\n","\n","# Most likely place of code breaking; had an error earlier stating that best_score\n","# does not exist, which I'd assume is because rnd_search had scoring=None. \n","# However, the solutions didn't pass it a scorer either so...?\n","rnd_search.best_params_\n","rnd_search.best_score_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yLS-4kHXORg"},"source":["# Check accuracy of best build on the test set\n","from sklearn.metrics import accuracy_score\n","rnd_search_predictions = rnd_search.predict(X_test)\n","accuracy = accuracy_score(y_test, rnd_search_predictions)\n","print(\"Accuracy: %.4f\" % accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8EROI-NedUw"},"source":["# Shift and add data\n","from scipy.ndimage import shift\n","\n","# Create copy to prevent messing with original training set\n","X_train_augmented = [image for image in X_train]\n","y_train_augmented = [label for label in y_train]\n","\n","for image in X_train:\n","  # Temporary variables not really necessary, used for readability\n","  # Shift data (reshape([-1]) apparently undoes the changes)\n","  up_transformed = shift(image.reshape(28, 28), [-1, 0].reshape([-1]))\n","  right_transformed = shift(image.reshape(28, 28), [0, 1].reshape([-1]))\n","  down_transformed = shift(image.reshape(28, 28), [-1, 0].reshape([-1]))\n","  left_transformed = shift(image.reshape(28, 28), [-1, 0].reshape([-1]))\n","  # Add data\n","  X_train_augmented.append(up_transformed)\n","  X_train_augmented.append(right_transformed)\n","  X_train_augmented.append(down_transformed)\n","  X_train_augmented.append(left_transformed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xpfz5W4-FSEw"},"source":["# Convert to array to prepare for shuffling\n","X_train_augmented = np.array(X_train_augmented)\n","y_train_augmented = np.array(y_train_augmented)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b0Uoo7IpB7zC"},"source":["# Shuffle training set (use shuffle_idx to shuffle the data and labels the same way)\n","shuffle_idx = np.random.permutation(len(X_train_augmented))\n","X_train_augmented = X_train_augmented[shuffle_idx]\n","y_train_augmented = y_train_augmented[shuffle_idx]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9UgnunwCtI8"},"source":["# Create new classifier\n","knn_clf = KNeighborsClassifier(**grid_search.best_params_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wanHmhyQCxJP"},"source":["# Retrain on new data\n","knn_clf.fit(X_train_augmented, y_train_augmented)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bxZNPfoC80i"},"source":["# Test accuracy on new data\n","knn_clf_predictions = knn_clf.predict(X_test)\n","accuracy_score(y_test, knn_clf_predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tWpQYGuCScc-"},"source":["# Error analysis: (leaving these next two blocks in because if they work that's a plus)\n","y_predicted = cross_val_predict(knn_clf, X_train, y_train, cv=3)\n","confusion_mx = confusion_matrix(y_train, y_predicted)\n","print(confusion_mx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJh_rJYLya-y"},"source":["# Visualization: \n","# normalize the confusion matrix so we see error rates instead of absolute numbers\n","row_sums = confusion_mx.sum(axis=1, keepdims=True)\n","confusion_mx_normed = confusion_mx / row_sums\n","\n","np.fill_diagonal(norm_conf_mx, 0)   # get rid of the diagonal (correct answers)\n","                                    # so we can focus on the errors\n","\n","np.fill_diagonal(norm_conf_mx, 0)\n","plt.matshow(confusion_mx_normed, cmap=plt.cm.gray)\n","plt.show()"],"execution_count":null,"outputs":[]}]}